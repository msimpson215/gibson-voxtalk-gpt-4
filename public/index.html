<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Gibson Voice Demo</title>
  <link rel="stylesheet" href="/styles.css" />
</head>

<body>
  <div class="bg"></div>
  <div class="scrim"></div>

  <!-- ‚ÄúInserted tab‚Äù in the same row vibe -->
  <div class="navWrap" aria-label="AI nav tab">
    <button class="navTab" id="navTab" type="button" aria-label="Try our new AI Gibson Specialist">
      <span class="navDot" aria-hidden="true"></span>
      <span class="navMain">Gibson Specialist</span>
      <span class="navSub">Try our new AI Gibson Specialist</span>
    </button>
  </div>

  <!-- mic circle -->
  <button class="micBubble" id="micBubble" type="button" title="Click to talk" aria-label="Click to talk">
    <img class="micImg" id="micImg" src="/assets/mic.png" alt=""
      onerror="this.style.display='none'; document.getElementById('micFallback').style.display='grid';">
    <span class="micFallback" id="micFallback" aria-hidden="true">üéôÔ∏è</span>
  </button>

  <!-- products -->
  <section class="cardsPanel" id="cardsPanel" aria-label="Product results">
    <header class="cardsTop">
      <div class="cardsTitle" id="cardsTitle">Matches</div>
      <div class="cardsActions">
        <button class="smallBtn" id="moreBtn" type="button">More</button>
        <button class="smallBtn" id="hideBtn" type="button">Hide</button>
      </div>
    </header>
    <div id="prodGrid"></div>
  </section>

  <!-- tiny debug (helps prove transcript is arriving) -->
  <div class="dbg" id="dbg"></div>

  <script src="/gipson.js"></script>
  <script>
    const navTab = document.getElementById("navTab");
    const micBubble = document.getElementById("micBubble");
    const cardsPanel = document.getElementById("cardsPanel");
    const cardsTitle = document.getElementById("cardsTitle");
    const moreBtn = document.getElementById("moreBtn");
    const hideBtn = document.getElementById("hideBtn");
    const dbg = document.getElementById("dbg");

    function dbgShow(s){
      dbg.textContent = s;
      dbg.classList.add("show");
      clearTimeout(dbg._t);
      dbg._t = setTimeout(()=>dbg.classList.remove("show"), 4200);
    }

    function triggerProducts(query, source){
      const q = String(query || "").trim();
      if(!q) return;
      dbgShow(`${source}: ${q}`);
      cardsTitle.textContent = `Showing: ${q}`;
      window.__gipson_showProducts?.(q);
      cardsPanel.classList.add("show");
    }

    navTab.addEventListener("click", () => {
      micBubble.classList.toggle("show");
      if (micBubble.classList.contains("show")) window.__gipson_loadCatalog?.();
    });

    hideBtn.addEventListener("click", () => cardsPanel.classList.remove("show"));
    moreBtn.addEventListener("click", () => {
      window.__gipson_moreResults?.();
      cardsPanel.classList.add("show");
    });

    // ---------- Voice (WebRTC Realtime) ----------
    let pc=null, dc=null, localStream=null, audioEl=null, starting=false;

    function hardReset(){
      try{ if(dc) dc.close(); }catch{}
      dc=null;
      try{
        if(pc){
          for(const s of pc.getSenders()){
            try{ if(s.track) s.track.stop(); }catch{}
          }
        }
      }catch{}
      try{ if(pc) pc.close(); }catch{}
      pc=null;

      if(localStream){
        localStream.getTracks().forEach(t=>{ try{ t.stop(); }catch{} });
      }
      localStream=null;

      if(audioEl){
        try{ audioEl.srcObject=null; }catch{}
        try{ audioEl.remove(); }catch{}
      }
      audioEl=null;
    }

    function stopVoice(){
      starting=false;
      micBubble.classList.remove("on");
      hardReset();
    }

    function sendEvent(obj){
      if(!dc || dc.readyState!=="open") return;
      dc.send(JSON.stringify(obj));
    }

    async function startVoice(){
      if(starting || pc) return;
      starting=true;
      micBubble.classList.add("on");
      hardReset();

      pc = new RTCPeerConnection();
      audioEl = document.createElement("audio");
      audioEl.autoplay = true;
      pc.ontrack = (e)=>{ audioEl.srcObject = e.streams[0]; };

      localStream = await navigator.mediaDevices.getUserMedia({ audio:true });
      pc.addTrack(localStream.getTracks()[0]);

      dc = pc.createDataChannel("oai-events");

      dc.onopen = () => {
        starting=false;

        // Enable transcription (this is OFF by default unless you set it)
        // Docs: input_audio_transcription configured via session.update. :contentReference[oaicite:1]{index=1}
        sendEvent({
          type:"session.update",
          session:{
            input_audio_transcription: { model: "whisper-1" },
            instructions:
              "You are Gibson's friendly, no-pressure guitar specialist. Always respond in English. " +
              "Keep answers short. Never claim the UI is showing something unless the user confirms they see it."
          }
        });

        sendEvent({
          type:"response.create",
          response:{ modalities:["audio","text"], instructions:"Quick greeting. Ask what guitar they want." }
        });
      };

      dc.onmessage = (e) => {
        try{
          const evt = JSON.parse(e.data);

          // ‚úÖ Correct transcription event + field:
          // conversation.item.input_audio_transcription.completed has `transcript` :contentReference[oaicite:2]{index=2}
          if (evt.type === "conversation.item.input_audio_transcription.completed" && evt.transcript) {
            triggerProducts(evt.transcript, "you");
          }

          // Also accept delta/segment forms (some models emit these) :contentReference[oaicite:3]{index=3}
          if (evt.type === "conversation.item.input_audio_transcription.delta" && evt.transcript) {
            // whisper-1 often sends full turns even in delta; safe to trigger
            triggerProducts(evt.transcript, "you");
          }
          if (evt.type === "conversation.item.input_audio_transcription.segment" && evt.text) {
            triggerProducts(evt.text, "you");
          }

          // Optional: if assistant outputs [[SHOW: ...]] in text
          if (evt.type === "response.output_text.done" && evt.text) {
            const m = String(evt.text).match(/\[\[\s*SHOW\s*:\s([^\]]+)\]\]/i);
            if (m && m[1]) triggerProducts(m[1].trim(), "SHOW");
          }
        }catch(_){}
      };

      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const sdpResp = await fetch("/session", {
        method:"POST",
        body: offer.sdp,
        headers:{ "Content-Type":"application/sdp" }
      });

      if(!sdpResp.ok){
        console.error("Session failed:", await sdpResp.text());
        stopVoice();
        return;
      }

      const answer = { type:"answer", sdp: await sdpResp.text() };
      await pc.setRemoteDescription(answer);
    }

    micBubble.addEventListener("click", async () => {
      if(pc) return stopVoice();
      try { await startVoice(); }
      catch(e){ console.error(e); stopVoice(); }
    });

    // preload catalog so ‚Äúblank page‚Äù never happens
    window.__gipson_loadCatalog?.();
  </script>
</body>
</html>
